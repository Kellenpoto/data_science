{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer neural networks are a current hot-topic in machine learning. The multilayer perceptron was the first standardized architecture.  In this assignment, you will learn to tune a [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) model.\n",
    "\n",
    "There are many libraries for using neural networks, but there isn't yet a single standard.  [Tensorflow](https://www.tensorflow.org/) is used by many, with [Keras](https://keras.io/) as one of the official APIs.\n",
    "\n",
    "\n",
    "## Part 1: Installation, and Introduction to Keras\n",
    "\n",
    "We'll be installing Keras and Tensorflow using a Docker container.  You could install Tensorflow natively (see [here](https://www.tensorflow.org/install/pip)) but Tensforflow typically causes downgrades in the Anaconda environment, and it has screwed up students'  Anaconda distribution in the past.\n",
    "\n",
    "**NOTE** If you have a PC with an NVIDIA GPU, and you want to train on it (highly recommended if you're pursuing a neural-net based capstone project), then you'll want to install `nvidia-docker` instead.  Go to the end of this assignment (the bottom of this page) and follow the install directions there.\n",
    "\n",
    "So, on with the Docker install:\n",
    "* Go to the home directory in your Terminal.  \n",
    "  ```bash\n",
    "  $ cd ~\n",
    "  ```\n",
    "\n",
    "* Start a Jupyter server on a `Docker` instance with Tensorflow 2.0 installed. This will pull the image from Docker Hub and make a container named `tensorflow`.\n",
    "\n",
    "    ```bash\n",
    "    $ docker run -it --name tensorflow -p 8888:8888 -v \"$PWD\":/tf tensorflow/tensorflow:2.0.0a0-py3-jupyter\n",
    "    ```\n",
    "  * After starting up the `docker` container and running the `Jupyter` notebook, you'll see a printout like:\n",
    "    ```\n",
    "    ...\n",
    "    To access the notebook, open this file in a browser:\n",
    "        file:///root/.local/share/jupyter/runtime/nbserver-10-open.html\n",
    "    Or copy and paste one of these URLs:\n",
    "        http://(ae4038ed94a3 or 127.0.0.1):8888/?token=e305929f1dca3ae69707f9a67d6467bd92ce3c1d6521919c\n",
    "    ```\n",
    "    \n",
    "    The hex number after `token=` is a password you need to access the notebook. In this case, it is `e305929f1dca3ae69707f9a67d6467bd92ce3c1d6521919c`, but yours will be different.\n",
    "  * Go to `http://localhost:8888` and enter in the password when prompted.\n",
    "  * If you use the above Docker command, the working directory will map to directory `/tf` in the container. The working directory of the Jupyter notebook in the container is `/tf`, and a useful Python script for this assignment in the `src` directory of this repository. Make sure that the `src` directory is in the Jupyter notebook's Python path, one way or another.\n",
    "\n",
    "* This Docker image (and the resulting container) has `numpy`, `keras`, and `tensorflow` packages.  However, it's lacking `pandas` and `sklearn`.  If you want to use them in this assignment, you'll have to access the container from the command line to install them.  Here's how you do that.  \n",
    "  ```bash\n",
    "  $ docker exec -it tensorflow /bin/bash\n",
    "  ```\n",
    "  Then from within the container:\n",
    "  ```bash\n",
    "  # pip install -U scikit-learn  \n",
    "  # pip install pandas\n",
    "  ```\n",
    "* For this assignment you have a couple of workflow options.  You could work in the Jupyter notebook.  Or, you can access the Tensorflow container from Terminal (as you did above) so that you can run a script from the command line.  To do this, in your Terminal access the running container in the bash shell using:  \n",
    "    ```bash\n",
    "    $ docker exec -it tensorflow /bin/bash\n",
    "    ```\n",
    "  Then from within the container:\n",
    "  ```bash\n",
    "  # python mlp.py\n",
    "  ```  \n",
    "  Or:\n",
    "  ```bash\n",
    "  # ipython\n",
    "  In [1]: run mlp.py\n",
    "  ```\n",
    "\n",
    "* Briefly read some example code for Multilayer Perceptron (the standard neural network) at http://keras.io/examples/. Note that these examples are out of date.  If you want to run the examples in the link, you need to import `keras` and supporting modules differently than what's shown in the examples.  Specifically, they need to be imported from `tensorflow`:\n",
    "\n",
    "    ```python\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building and tuning a neural network model\n",
    "\n",
    "In the Docker-backed Jupyter notebook/Terminal/Ipython console, use the `load_and_condition_MNIST_data` function in `src/mlp.py` to load a train and test set of images of hand-drawn digits.\n",
    "\n",
    "### Initial inspection\n",
    "\n",
    "```python\n",
    "from mlp import load_and_condition_MNIST_data\n",
    "X_train, y_train, X_test, y_test, y_train_onehot = load_and_condition_MNIST_data()\n",
    "```\n",
    "\n",
    "1. The shape of `X_train` is (n_samples, n_features). How many samples are there in the training set? How many in the test set? How many features are there per sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/  mlp_soln.py  notebook_assignment_solution.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded MNIST images\n",
      "\n",
      "First 5 labels of MNIST y_train:  [5 0 4 1 9]\n",
      "\n",
      "First 5 labels of MNIST y_train (one-hot):\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlp_soln import load_and_condition_MNIST_data\n",
    "X_train, y_train, X_test, y_test, y_train_onehot = load_and_condition_MNIST_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You may have noticed that each sample \"image\" is a row from the `X` matrix - it's a 1-dimensional array. Speculate on why this is a convenient way to store images."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because it allows us to know where the data is, change their shape, and put it into a NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Inspect a few of the sample images. (You may find the `np.reshape` and `ax.imshow` methods useful.) Inspect some of the corresponding labels from the labels `y_train`; you'll find that they're simply a number corresponding to the digit depicted in the image.\n",
    "\n",
    "Look at the `y_train_onehot` labels. What's going on there? We'll get to that soon.\n",
    "\n",
    "Our task is to use X_train and y_train to make a model that will accurately predict the labels in X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(X_train[0].reshape(-1,28), cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "If we conceptualize each image sample as a 1-dimensional vector, we can use any multiclass model available. For example, we could simply train a single decision tree:\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, yhat))\n",
    "```\n",
    "\n",
    "If you run this, you'll find a single decision tree can classify hand-drawn digits with about 88% accuracy. Pretty good for being so simple. That's the score to beat.\n",
    "\n",
    "Take a moment to discuss with your partner what each split in the decision tree means, and what it means for a decision tree to classify an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train[:10000,:], y_train[:10000])\n",
    "yhat = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Keras\n",
    "\n",
    "Maybe the simplest possible model in Keras a neural network with a single unit and no hidden layer:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=1,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "```\n",
    "\n",
    "1. Build this model, and **without training it**, use the `.predict(X_test)` method to predict the output label of the test set. What is the shape of the output of `predict`? Speculate about why this works, even if you haven't trained the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=1,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The shape is (10,000,1) because that is one value output per sample in X_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hmmm, but how can we _predict_ before we train? What are the weights? It would be impossible in a linear regression. (We would get an error, there would be no Betas!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f74c00b4128>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_unit_i = 0\n",
    "plt.imshow(denselayer.weights[0].numpy()[:,hidden_unit_i].reshape(28,28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It would seem that they're random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's look at the distribution of the _linear_ outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X_train @ model.get_weights()[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ok, they're normally distributed... Sooo randomish?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's look at the distribution of the _logistic_ outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.predict(X_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the output was random, but then got crunched into the sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The output of this model is the activation of a single \"neuron\" (aka \"unit\"), as a function of all 784 input pixel features. The output of the neuron is `activation_function( m*x+b )`, where `activation_function` is function specified in the `denselayer` layer, and `m` and `b` are the `.weights` and `.bias` members of the layer. Manually obtain the neuron's weight and bias, and use the pseudocode `activation_function( m*x+b )` to calculate the neuron's response to the first test example `X_test[0]`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.activations.sigmoid(x)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(index=0).activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7415, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(index=0).activation(X_test[0] @ model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find the output of a logistic regression model using `m` as the `beta` and `X_test[0]` as `x_i`. How to they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + 1 / np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma(X_test[0] @ model.get_weights()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> they're the same?!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The current model can't do multiclass prediction - it can only predict a single thing. Let's use it to predict if an image is a '1'. Create a binary label set `yone_train` and `yone_test` for images that are ones, and then train it like this:\n",
    "\n",
    "```\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=[Precision(), Recall()] ) \n",
    "\n",
    "model.fit(X_train, yone_train, epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)\n",
    "```\n",
    "\n",
    "Take a look at the `weight` and `bias` parameters of the `denselayer`. Have they changed? Now that you've considered the relationship of this neuron to logistic regression, how would you relate training this model to training a logistic regression model? (Consider taking the neuron's `weight` vector, reshaping it into a square, and rendering an image of it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 1s 24us/sample - loss: 7.8219 - precision: 0.6772 - recall: 0.6810 - accuracy: 0.9271 - val_loss: 0.7380 - val_precision: 0.9238 - val_recall: 0.9429 - val_accuracy: 0.9858\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 0s 6us/sample - loss: 0.8713 - precision: 0.9263 - recall: 0.9342 - accuracy: 0.9841 - val_loss: 0.5825 - val_precision: 0.9473 - val_recall: 0.9413 - val_accuracy: 0.9883\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 0s 6us/sample - loss: 0.7150 - precision: 0.9351 - recall: 0.9382 - accuracy: 0.9856 - val_loss: 0.4731 - val_precision: 0.9432 - val_recall: 0.9492 - val_accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 0s 6us/sample - loss: 0.6110 - precision: 0.9364 - recall: 0.9439 - accuracy: 0.9864 - val_loss: 0.4052 - val_precision: 0.9422 - val_recall: 0.9571 - val_accuracy: 0.9893\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 0s 5us/sample - loss: 0.5426 - precision: 0.9394 - recall: 0.9462 - accuracy: 0.9870 - val_loss: 0.3712 - val_precision: 0.9368 - val_recall: 0.9651 - val_accuracy: 0.9895\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 0s 6us/sample - loss: 0.4906 - precision: 0.9396 - recall: 0.9488 - accuracy: 0.9873 - val_loss: 0.3345 - val_precision: 0.9379 - val_recall: 0.9587 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 0s 7us/sample - loss: 0.4484 - precision: 0.9392 - recall: 0.9504 - accuracy: 0.9874 - val_loss: 0.3072 - val_precision: 0.9536 - val_recall: 0.9460 - val_accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 0s 5us/sample - loss: 0.4123 - precision: 0.9421 - recall: 0.9472 - accuracy: 0.9874 - val_loss: 0.2886 - val_precision: 0.9398 - val_recall: 0.9667 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 0s 7us/sample - loss: 0.3820 - precision: 0.9392 - recall: 0.9498 - accuracy: 0.9874 - val_loss: 0.2826 - val_precision: 0.9627 - val_recall: 0.9429 - val_accuracy: 0.9902\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 0s 5us/sample - loss: 0.3592 - precision: 0.9415 - recall: 0.9475 - accuracy: 0.9874 - val_loss: 0.2596 - val_precision: 0.9492 - val_recall: 0.9492 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f74d84eccc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yone_train = y_train==1\n",
    "yone_test = y_test==1\n",
    "\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=1,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=[Precision(), Recall(), 'accuracy'] ) \n",
    "\n",
    "model.fit(X_train, yone_train, epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.51113552e-03, -1.61494240e-02,  4.98741865e-03,\n",
       "        -1.35306343e-02,  4.09037583e-02,  4.51615341e-02,\n",
       "        -4.29510474e-02, -1.56362653e-02,  1.70658715e-02,\n",
       "         4.92255129e-02,  2.76861452e-02, -6.55674934e-03,\n",
       "         4.98711579e-02, -4.50650230e-02, -3.04171089e-02,\n",
       "         4.34661247e-02, -4.44931909e-03,  2.75762118e-02,\n",
       "        -2.60550026e-02,  1.50920190e-02,  2.78774612e-02,\n",
       "         1.06488839e-02,  4.75630648e-02,  2.05459110e-02,\n",
       "        -3.53593938e-02,  4.54674400e-02,  2.08733231e-03,\n",
       "         3.79588716e-02],\n",
       "       [-4.15684804e-02,  2.19164006e-02, -1.37005933e-02,\n",
       "        -1.48350000e-02, -3.56351621e-02, -3.73683870e-04,\n",
       "        -2.82211788e-02, -8.97929817e-03, -2.67670192e-02,\n",
       "         1.82492286e-02,  1.70883629e-02, -1.70346349e-02,\n",
       "        -8.50106217e-03,  9.84223909e-04,  1.09250788e-02,\n",
       "        -3.88185456e-02,  2.40636282e-02, -6.92306599e-03,\n",
       "        -9.18786856e-04,  8.88562761e-03, -2.61877757e-03,\n",
       "        -2.38839649e-02, -4.61227819e-03, -2.47647520e-02,\n",
       "        -4.82428782e-02,  1.94249488e-02,  5.82129881e-03,\n",
       "         2.76446231e-02],\n",
       "       [-2.16107443e-03, -1.01221725e-03, -2.79178862e-02,\n",
       "        -3.77433077e-02, -3.73692997e-02,  2.91074775e-02,\n",
       "         3.69848795e-02, -2.63088979e-02,  1.88109819e-02,\n",
       "         2.07074713e-02, -1.62791703e-02,  4.07694606e-03,\n",
       "        -1.38732148e-02,  3.43658775e-02, -4.36230935e-03,\n",
       "        -4.02612872e-02, -2.17875596e-02,  2.18126923e-02,\n",
       "        -2.95449211e-03, -6.84762886e-03, -2.42914166e-03,\n",
       "         1.92313064e-02,  1.44694019e-02, -3.14202197e-02,\n",
       "        -1.62627976e-02, -4.23492193e-02,  2.02063434e-02,\n",
       "        -2.31045838e-02],\n",
       "       [ 3.31219919e-02, -8.00565630e-03, -1.50350444e-02,\n",
       "        -3.22162732e-02, -3.01177632e-02, -4.36352519e-03,\n",
       "         1.11646892e-03,  7.84340780e-03,  1.54363713e-03,\n",
       "         2.82896832e-02,  2.39754897e-02,  3.36634666e-02,\n",
       "        -4.08483855e-02, -2.14911792e-02,  2.40463559e-02,\n",
       "         3.90065601e-04, -3.27428170e-02, -3.64746638e-02,\n",
       "         1.17000220e-02,  1.33395055e-02, -4.52059954e-02,\n",
       "        -3.00799916e-03,  8.03313404e-03, -2.01841979e-03,\n",
       "        -3.70755605e-02,  4.93048094e-02, -4.11945805e-02,\n",
       "         3.70623805e-02],\n",
       "       [-9.98399407e-03,  2.54493393e-02, -4.91668805e-02,\n",
       "         2.46449541e-02,  4.87067290e-02,  4.93861958e-02,\n",
       "        -4.79983985e-02, -5.12298718e-02, -1.60509441e-02,\n",
       "        -8.80977791e-03,  2.31045410e-02, -9.86534916e-03,\n",
       "         3.76250930e-02, -1.89030487e-02, -2.71417946e-02,\n",
       "         2.63711233e-02,  3.45502496e-02, -3.39108445e-02,\n",
       "         3.75288427e-02, -1.02599999e-02,  3.89118008e-02,\n",
       "         1.05641717e-02, -3.47241350e-02,  4.33494989e-03,\n",
       "         4.84505901e-03, -1.65811069e-02, -4.99692224e-02,\n",
       "         1.28487237e-02],\n",
       "       [ 8.17619637e-03, -2.66216155e-02, -4.71699350e-02,\n",
       "        -9.29893460e-03,  1.49134900e-02,  3.01078372e-02,\n",
       "         1.08218566e-02,  1.56370159e-02, -4.35821153e-02,\n",
       "        -1.89764127e-02, -5.34101240e-02, -1.78520828e-02,\n",
       "         1.10910516e-02, -2.13841833e-02,  1.91367010e-03,\n",
       "         2.84561124e-02, -1.72442775e-02, -1.74981244e-02,\n",
       "         9.54920612e-03, -3.87700722e-02,  7.44759012e-03,\n",
       "        -1.54032977e-02,  2.04628110e-02,  4.29697372e-02,\n",
       "         1.97973568e-03, -2.93187853e-02, -2.21792236e-02,\n",
       "         2.63263844e-02],\n",
       "       [-1.60288215e-02, -3.68953459e-02, -4.21607755e-02,\n",
       "        -3.10684964e-02,  4.50171977e-02,  3.63940001e-02,\n",
       "        -3.54384929e-02,  1.75816305e-02,  2.78285928e-02,\n",
       "        -3.53798755e-02, -6.39144098e-03, -2.08091550e-03,\n",
       "        -2.36669127e-02,  9.12705529e-03, -2.64592795e-03,\n",
       "         4.01276629e-03, -3.40423547e-02,  1.33374361e-02,\n",
       "        -3.83705087e-02,  1.68965273e-02,  1.93800572e-02,\n",
       "         2.67748181e-02, -2.62791328e-02, -4.27758098e-02,\n",
       "         2.82161888e-02, -4.84339744e-02, -7.53325364e-03,\n",
       "        -4.42129374e-03],\n",
       "       [-4.13672440e-02,  3.71981524e-02, -4.02735844e-02,\n",
       "         2.33486164e-02, -2.84708943e-02, -2.81712674e-02,\n",
       "         9.02028847e-03, -2.37348792e-03, -5.27533405e-02,\n",
       "         2.03392562e-02,  2.30502859e-02, -4.93924096e-02,\n",
       "        -1.95886828e-02, -8.65444075e-04, -8.07478651e-03,\n",
       "        -1.90211460e-02, -5.07094897e-03,  3.37177934e-03,\n",
       "         2.24119574e-02,  1.56374089e-02,  2.11935416e-02,\n",
       "         3.29998098e-02,  2.60753604e-03,  2.12706383e-02,\n",
       "        -8.90568458e-03, -5.00562675e-02,  1.90306045e-02,\n",
       "        -1.24814138e-02],\n",
       "       [-3.11201457e-02,  4.85695861e-02, -2.53504645e-02,\n",
       "        -4.60534841e-02, -2.69877315e-02, -7.09945103e-03,\n",
       "        -1.54058374e-02, -3.26225460e-02,  6.21011155e-03,\n",
       "        -6.49475604e-02, -5.61437430e-03, -5.24294600e-02,\n",
       "         2.66768336e-02, -2.84859668e-02, -4.41758782e-02,\n",
       "        -1.32958805e-02, -3.15119401e-02, -1.73182096e-02,\n",
       "        -4.25660843e-03, -4.26539555e-02, -3.56499292e-02,\n",
       "         1.34360781e-02, -1.53296208e-02, -5.46921231e-02,\n",
       "        -3.51903290e-02, -4.54309247e-02,  2.59695984e-02,\n",
       "        -1.39241321e-02],\n",
       "       [-4.22705896e-02,  1.26604475e-02,  2.60290783e-02,\n",
       "        -2.26734150e-02,  1.24427825e-02, -3.81772295e-02,\n",
       "        -3.89482155e-02, -5.36032729e-02,  2.57641785e-02,\n",
       "         2.15814114e-02, -4.32434492e-02, -3.52660380e-02,\n",
       "         4.23065275e-02, -2.15787366e-02,  3.63960415e-02,\n",
       "         2.63295006e-02, -1.25507051e-02,  2.31606830e-02,\n",
       "         3.77964973e-02, -5.13692982e-02,  1.60277337e-02,\n",
       "        -6.60914630e-02,  9.62566677e-03, -4.60798386e-03,\n",
       "         2.60975603e-02,  3.89416069e-02,  1.85759198e-02,\n",
       "         4.94043753e-02],\n",
       "       [-1.41448490e-02, -1.58003084e-02,  9.44905076e-03,\n",
       "         1.11021325e-02,  2.47206818e-02, -9.70988907e-03,\n",
       "        -1.67864673e-02, -3.96417007e-02, -3.60682905e-02,\n",
       "        -2.55160518e-02, -1.67762674e-02, -9.56622139e-03,\n",
       "        -1.36867538e-02, -4.66445647e-03,  5.08728847e-02,\n",
       "         1.58057567e-02, -4.03551338e-03, -3.61807607e-02,\n",
       "        -3.96300592e-02,  2.88077686e-02, -2.90664006e-02,\n",
       "        -1.84996706e-02, -6.27422184e-02, -1.71117447e-02,\n",
       "         1.13720447e-02,  3.70042697e-02, -2.90756971e-02,\n",
       "        -6.67990046e-03],\n",
       "       [-3.44585627e-04, -1.16352048e-02,  3.43454294e-02,\n",
       "         1.59324426e-02,  7.66288908e-03, -1.60877779e-02,\n",
       "        -2.50752885e-02,  2.60007456e-02, -3.45358849e-02,\n",
       "        -4.85250987e-02,  1.51921399e-02, -4.11838666e-02,\n",
       "         1.09321568e-02,  6.14881814e-02,  4.97331806e-02,\n",
       "         1.68984737e-02,  3.20564560e-03,  3.48864123e-02,\n",
       "         2.54881214e-02, -1.56834628e-02, -1.49896024e-02,\n",
       "         1.69256690e-03,  2.11249683e-02, -5.44560608e-03,\n",
       "         4.48928215e-02, -1.82989391e-03, -5.15842857e-03,\n",
       "        -3.97983119e-02],\n",
       "       [-4.77132909e-02, -5.14490530e-03,  4.01018187e-02,\n",
       "         1.83205977e-02, -3.72460224e-02, -2.35836860e-02,\n",
       "         3.82020921e-02,  3.08189262e-02, -4.52892520e-02,\n",
       "        -4.13679555e-02,  2.29563899e-02, -5.47597110e-02,\n",
       "        -3.34816352e-02, -2.36300658e-02,  7.12700700e-03,\n",
       "         5.10117486e-02, -1.67395885e-03, -3.15307975e-02,\n",
       "        -1.19121065e-02, -6.82085529e-02,  2.63792239e-02,\n",
       "        -1.97902415e-02, -2.02522315e-02,  1.66538749e-02,\n",
       "         4.71988767e-02,  9.56301391e-03, -6.95527112e-03,\n",
       "         1.68771539e-02],\n",
       "       [ 3.09775025e-03,  3.95026468e-02,  1.84428357e-02,\n",
       "        -4.07587104e-02,  2.62509119e-02,  3.70746441e-02,\n",
       "        -1.10740596e-02, -6.36161864e-02, -1.94174945e-02,\n",
       "        -7.54432520e-04, -4.19971831e-02, -8.50361586e-03,\n",
       "         9.46971867e-03,  3.64430770e-02,  6.77061230e-02,\n",
       "         4.80366014e-02,  8.22156761e-03,  4.40625194e-03,\n",
       "         1.32590272e-02, -6.22578822e-02,  2.10026763e-02,\n",
       "        -2.84925960e-02,  3.48906443e-02,  1.40579846e-02,\n",
       "        -4.22976725e-03,  3.66959088e-02, -2.70558894e-02,\n",
       "        -4.05703858e-03],\n",
       "       [ 1.65412687e-02, -3.98379080e-02, -4.85643521e-02,\n",
       "        -2.60331761e-02,  3.81243192e-02,  1.14628393e-02,\n",
       "         3.73369170e-04, -5.49037941e-02, -8.12921580e-03,\n",
       "        -8.05917196e-04,  1.22339511e-02, -4.16368060e-02,\n",
       "         2.08504498e-02, -2.83800587e-02,  3.14324833e-02,\n",
       "         2.43621767e-02, -1.48508260e-02, -4.26607765e-02,\n",
       "         1.80979236e-03, -3.70437093e-02, -6.98049963e-02,\n",
       "        -6.01978265e-02, -1.09035149e-02,  1.82548221e-02,\n",
       "        -4.79126088e-02, -2.03495426e-03,  4.82784305e-03,\n",
       "        -2.96996366e-02],\n",
       "       [ 1.39964931e-02,  4.97705601e-02,  2.57905833e-02,\n",
       "        -1.83885302e-02, -1.53071322e-02, -1.05139222e-02,\n",
       "        -4.33165245e-02, -2.04636455e-02,  2.12614727e-03,\n",
       "        -6.46649078e-02, -3.17041129e-02, -1.77064221e-02,\n",
       "         4.63831285e-03,  1.38831334e-02,  1.75386330e-03,\n",
       "         3.83417159e-02,  4.81488736e-04, -5.97901046e-02,\n",
       "        -2.49519479e-02, -2.86248308e-02,  3.01333470e-03,\n",
       "        -8.80838837e-03,  2.55289208e-03,  1.08443934e-03,\n",
       "         4.46797833e-02, -2.46501118e-02, -2.45392509e-02,\n",
       "         3.00081111e-02],\n",
       "       [ 2.34764926e-02, -5.06319164e-04, -1.64552759e-02,\n",
       "         2.09597461e-02, -1.39860939e-02, -2.18024831e-02,\n",
       "        -4.21293713e-02, -1.26037784e-02, -5.48112113e-03,\n",
       "        -5.98232821e-02, -2.88900137e-02,  1.04354043e-02,\n",
       "         2.18759160e-02, -1.89496577e-02,  4.36391160e-02,\n",
       "        -1.75769981e-02,  3.54567170e-02, -5.97805232e-02,\n",
       "        -4.73021790e-02, -1.09999143e-02, -3.53400456e-03,\n",
       "        -4.71462868e-02,  3.18112075e-02, -1.00435466e-02,\n",
       "         2.08367687e-03, -5.35628060e-03, -3.26629728e-02,\n",
       "         3.82167809e-02],\n",
       "       [ 2.74700187e-02,  2.17841882e-02,  4.03502844e-02,\n",
       "        -2.00934839e-02, -4.13884707e-02, -4.68314998e-02,\n",
       "        -5.49598411e-03,  9.54591110e-03, -2.81297266e-02,\n",
       "        -2.00153645e-02,  1.97011493e-02, -5.08783050e-02,\n",
       "         6.34594075e-03,  7.65484874e-04,  3.38171907e-02,\n",
       "         3.89448628e-02, -1.22466693e-02, -3.00292820e-02,\n",
       "         7.18784577e-06, -4.24463972e-02, -6.34480491e-02,\n",
       "         1.57555006e-02, -6.06261827e-02, -1.31586557e-02,\n",
       "        -2.01877635e-02,  3.24550979e-02,  1.96687002e-02,\n",
       "        -4.36781310e-02],\n",
       "       [-4.07870151e-02, -1.30257290e-03, -3.73505652e-02,\n",
       "        -4.19155397e-02, -3.63511895e-03, -3.67754549e-02,\n",
       "        -4.13240604e-02, -6.36056438e-02, -1.69016270e-03,\n",
       "         1.57407429e-02, -1.10694766e-02,  2.41709724e-02,\n",
       "         3.25461254e-02, -1.00598615e-02, -2.44831089e-02,\n",
       "        -4.22690101e-02, -4.86609293e-03, -1.71725880e-02,\n",
       "        -4.70715500e-02, -1.55515578e-02,  2.53170654e-02,\n",
       "        -5.20567559e-02, -5.47424667e-02,  1.51234400e-02,\n",
       "        -3.91705073e-02, -1.92153621e-02,  3.88453528e-02,\n",
       "        -1.63041695e-03],\n",
       "       [-3.67952399e-02,  4.23231125e-02, -2.02147895e-03,\n",
       "        -4.68613356e-02,  2.33265683e-02,  7.76840001e-03,\n",
       "        -9.05224588e-03, -1.09061319e-02, -5.02307387e-03,\n",
       "        -3.00024133e-02, -5.19757345e-02, -2.05072742e-02,\n",
       "        -4.45767213e-03,  2.01669689e-02,  3.85046974e-02,\n",
       "         3.81447002e-02, -2.33465508e-02,  1.38605935e-02,\n",
       "        -1.03175621e-02, -3.19950581e-02, -3.26990746e-02,\n",
       "         3.86012942e-02,  2.64379531e-02, -2.74261404e-02,\n",
       "         3.47271413e-02,  2.90462491e-03, -2.24392340e-02,\n",
       "        -2.51418073e-02],\n",
       "       [-1.21936686e-02, -1.17447944e-02, -4.88558784e-02,\n",
       "         1.41635202e-02, -5.04692867e-02, -4.34227958e-02,\n",
       "         1.18607702e-02, -1.61373662e-03, -3.92628759e-02,\n",
       "         2.19064094e-02,  6.49848429e-04,  1.67898834e-02,\n",
       "        -2.43188068e-02, -4.18534093e-02, -2.79810391e-02,\n",
       "        -4.37265970e-02, -2.67776614e-03,  1.31519297e-02,\n",
       "         2.34730449e-02, -2.12016925e-02,  1.94843505e-02,\n",
       "        -2.28182543e-02, -2.69953348e-02,  1.08977938e-02,\n",
       "        -2.67270133e-02,  4.88983886e-03, -2.61949172e-04,\n",
       "        -7.34275579e-03],\n",
       "       [-4.73953858e-02, -8.93566385e-03, -1.08824465e-02,\n",
       "        -3.60118039e-02,  3.49526107e-02,  3.42729241e-02,\n",
       "        -4.74302238e-03, -2.99360417e-02, -2.61534099e-02,\n",
       "        -2.91403569e-03, -1.28897708e-02, -3.45382839e-02,\n",
       "         1.71926729e-02, -3.64607535e-02,  2.91508362e-02,\n",
       "        -2.64422372e-02,  2.79937051e-02,  9.91818774e-03,\n",
       "        -1.67088807e-02,  3.85138988e-02, -3.00581325e-02,\n",
       "        -1.02079837e-02,  2.48659290e-02, -3.59620564e-02,\n",
       "        -3.49700116e-02, -3.86277661e-02,  4.46618833e-02,\n",
       "         3.44395973e-02],\n",
       "       [-5.19561768e-03, -4.79264222e-02,  7.97222648e-03,\n",
       "        -6.62903022e-03, -3.84143218e-02,  8.24639667e-03,\n",
       "         5.16846403e-02, -4.12778147e-02,  5.80759905e-02,\n",
       "        -3.52681167e-02,  8.40377994e-03, -3.87311280e-02,\n",
       "        -4.82678562e-02,  7.55095948e-03,  1.22727798e-02,\n",
       "        -5.22572771e-02,  7.06799794e-03, -1.46401320e-02,\n",
       "         1.44194961e-02, -9.19930451e-03, -4.19955440e-02,\n",
       "        -6.76657399e-03,  4.58697462e-03, -2.61499267e-02,\n",
       "        -4.85431701e-02,  4.97043915e-02,  2.07940936e-02,\n",
       "         1.71056874e-02],\n",
       "       [-3.03053018e-02, -2.95516010e-02,  9.95583739e-03,\n",
       "        -1.95288891e-03, -1.75802372e-02,  4.14728895e-02,\n",
       "        -1.54796829e-02,  1.82801522e-02, -1.85964964e-02,\n",
       "        -1.75167080e-02,  1.94940101e-02, -4.79062237e-02,\n",
       "        -5.20464256e-02,  9.93520115e-03, -4.73600551e-02,\n",
       "         1.69384722e-02, -2.71920599e-02,  3.40268463e-02,\n",
       "        -3.30866314e-02,  8.92603397e-03, -3.31226573e-03,\n",
       "        -4.95332740e-02,  3.05089690e-02,  1.70213338e-02,\n",
       "        -1.41311632e-02,  4.09119315e-02,  1.58777426e-03,\n",
       "         2.92053074e-03],\n",
       "       [-3.13108452e-02, -3.09778452e-02, -4.15740721e-02,\n",
       "         4.78690118e-02,  3.52205224e-02, -9.79372486e-03,\n",
       "         7.79344887e-03, -1.61856879e-02,  4.40812949e-03,\n",
       "         7.79282534e-03, -2.90670991e-02,  8.57358146e-03,\n",
       "        -2.32867971e-02, -5.93406446e-02,  3.96365020e-03,\n",
       "        -3.95497717e-02, -3.54833789e-02, -1.00147817e-02,\n",
       "        -3.76703292e-02, -4.18156646e-02, -2.67687012e-02,\n",
       "        -2.14859704e-03,  4.83707152e-02, -4.50429879e-03,\n",
       "         3.26833315e-03,  4.18728329e-02, -4.80673313e-02,\n",
       "        -2.13469509e-02],\n",
       "       [ 1.59040727e-02,  1.47639550e-02, -3.64686176e-03,\n",
       "        -1.07793808e-02, -1.40040815e-02, -1.89748611e-02,\n",
       "        -5.00180051e-02, -4.53598499e-02, -1.78759098e-02,\n",
       "        -2.06725250e-04,  3.76413167e-02, -1.51441684e-02,\n",
       "        -4.98452261e-02, -4.09853719e-02,  1.53745497e-02,\n",
       "         3.56514640e-02,  8.77974741e-03, -3.42775024e-02,\n",
       "        -1.53684458e-02,  6.09588111e-03,  1.29085248e-02,\n",
       "        -3.43737416e-02, -2.91047413e-02, -2.70730164e-03,\n",
       "         4.11664434e-02, -3.76754999e-03, -3.64465490e-02,\n",
       "         1.15755685e-02],\n",
       "       [ 4.27420773e-02, -2.16894746e-02,  1.35183334e-04,\n",
       "         4.37768213e-02, -4.02166732e-02, -5.04032522e-03,\n",
       "        -1.65612455e-02, -3.12157883e-03, -3.12156267e-02,\n",
       "        -4.94083762e-02,  1.90953948e-02,  1.28120650e-02,\n",
       "         4.49334877e-03,  2.84668598e-02, -2.23749541e-02,\n",
       "         2.24257223e-02,  7.94741884e-03, -4.97796275e-02,\n",
       "        -4.41966094e-02,  4.56060804e-02, -1.00631341e-02,\n",
       "         2.05729268e-02,  3.11509855e-02, -1.04231015e-02,\n",
       "        -1.83494911e-02, -2.46004015e-03,  2.15709209e-03,\n",
       "        -2.99547315e-02],\n",
       "       [ 1.74901821e-02, -6.23422861e-03,  9.56101343e-03,\n",
       "        -3.41983810e-02,  3.31662931e-02, -1.86889172e-02,\n",
       "         3.58882882e-02,  4.04446833e-02, -3.70206609e-02,\n",
       "        -2.08650492e-02,  6.18671812e-03,  1.33343674e-02,\n",
       "         1.15970848e-02, -4.71561961e-02,  3.94526199e-02,\n",
       "         1.81219615e-02,  4.67623137e-02,  3.97643931e-02,\n",
       "         1.84475444e-02,  4.56395186e-02, -4.02627140e-03,\n",
       "         4.75709513e-03, -3.69936712e-02, -3.51720825e-02,\n",
       "        -1.72978863e-02, -2.51631029e-02,  1.97190531e-02,\n",
       "        -3.49911936e-02]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0].numpy()[:,hidden_unit_i].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f74d86985c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_unit_i = 0\n",
    "plt.imshow(model.weights[0].numpy()[:,hidden_unit_i].reshape(28,28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Theres a dark spot in the middle! Looking for that vertical line, and it's very white on the sides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression in parallel\n",
    "\n",
    "Keras allows us to perform logistic regression _in parallel_ for a large number of target classes:\n",
    "\n",
    "```python\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=10,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"sgd\", metrics=[\"accuracy\"] )\n",
    "```\n",
    "\n",
    "1. Compile and train this model. What test accuracy does it converge to? Is it good or bad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 1s 24us/sample - loss: 4.0182 - accuracy: 0.1601 - val_loss: 2.3763 - val_accuracy: 0.1882\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 2.3421 - accuracy: 0.1811 - val_loss: 2.2868 - val_accuracy: 0.1870\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 13us/sample - loss: 2.2932 - accuracy: 0.1834 - val_loss: 2.2681 - val_accuracy: 0.1892\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 10us/sample - loss: 2.2737 - accuracy: 0.1870 - val_loss: 2.2578 - val_accuracy: 0.1917\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 10us/sample - loss: 2.2616 - accuracy: 0.1907 - val_loss: 2.2490 - val_accuracy: 0.1953\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 10us/sample - loss: 2.2528 - accuracy: 0.1956 - val_loss: 2.2425 - val_accuracy: 0.1995\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 11us/sample - loss: 2.2457 - accuracy: 0.2003 - val_loss: 2.2365 - val_accuracy: 0.2048\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 9us/sample - loss: 2.2390 - accuracy: 0.2070 - val_loss: 2.2310 - val_accuracy: 0.2102\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 0s 9us/sample - loss: 2.2329 - accuracy: 0.2129 - val_loss: 2.2252 - val_accuracy: 0.2153\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 0s 9us/sample - loss: 2.2268 - accuracy: 0.2183 - val_loss: 2.2195 - val_accuracy: 0.2222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f354a706550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=10,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=\"sgd\", metrics=[\"accuracy\"] )\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 1.        , 1.        , 0.9997985 ,\n",
       "       1.        , 1.        , 1.        , 0.99997675, 1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the model to find a probabilistic prediction on any item in `X_test`. What is the _sum of probabilities_ for every predicted class?\n",
    "\n",
    "You'll notice the predictions are hot garbage (with an accuracy around 20%), and that the class probabilities for every class sum to more than 1.0.\n",
    "\n",
    "One solution is to apply a function to the neuron outputs that normalizes the vector such that it's constrained to add up to 1.0, and then on a loss from _that_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5870.704 , 6997.9746, 8427.09  , 9522.488 , 9605.1   , 9973.965 ,\n",
       "       9619.411 , 9409.269 , 9722.523 , 9877.384 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 1.        , ..., 1.        , 0.99997675,\n",
       "        1.        ],\n",
       "       [0.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.        , 1.        , 1.        , ..., 0.47325078, 1.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [1.        , 0.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Change the `activation` argument to \"softmax\", and retrain the model. What is the test accuracy? What is the sum of classification probabilities for all classes, for a single prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 1s 16us/sample - loss: 186.8225 - accuracy: 0.4214 - val_loss: 26.8597 - val_accuracy: 0.7410\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 1s 11us/sample - loss: 28.0254 - accuracy: 0.7536 - val_loss: 14.4070 - val_accuracy: 0.8430\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 12us/sample - loss: 12.2037 - accuracy: 0.8477 - val_loss: 10.0931 - val_accuracy: 0.8645\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 13us/sample - loss: 20.5367 - accuracy: 0.7897 - val_loss: 18.4241 - val_accuracy: 0.8105\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 12us/sample - loss: 16.3915 - accuracy: 0.8130 - val_loss: 7.6938 - val_accuracy: 0.8898\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 11us/sample - loss: 8.8445 - accuracy: 0.8723 - val_loss: 10.2794 - val_accuracy: 0.8470\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 0s 9us/sample - loss: 17.8096 - accuracy: 0.8051 - val_loss: 27.2423 - val_accuracy: 0.7455\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 14us/sample - loss: 18.4806 - accuracy: 0.7981 - val_loss: 9.3148 - val_accuracy: 0.8755\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 1s 15us/sample - loss: 7.9707 - accuracy: 0.8826 - val_loss: 6.1653 - val_accuracy: 0.8967\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 1s 22us/sample - loss: 19.7877 - accuracy: 0.8055 - val_loss: 18.7631 - val_accuracy: 0.8233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3561096320>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "denselayer = Dense(units=10,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(denselayer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"sgd\", metrics=[\"accuracy\"] )\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=5000, verbose=1,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit: train with a large `batch` argument in `.fit`, and make pictures of the unit weights reshaped into 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons: logistic regression with hidden features\n",
    "\n",
    "A perceptron is an architecture whereby an input is classified into a number of features; features that are actually unknown when model training begins. Then, logistic regression (or softmax regression) using the _hidden features_ as inputs is used to find the final class probabilities. This architecture is called a \"perceptron\", \"multiplayer perceptron\", or \"MLP\". Here's how to define an MLP with 300 neurons in one hidden layer, using Keras:\n",
    "\n",
    "```python\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "hidden_units = 300\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='constant',\n",
    "                activation='sigmoid')\n",
    "\n",
    "output_layer = Dense(units=n_classes,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "model.add(output_layer)\n",
    "```\n",
    "\n",
    "1. Compile and train this model on the MNIST dataset. The 'adam' optimizer tends to do well. What kind of accuracy do you get? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 17s 283us/sample - loss: 0.4297 - accuracy: 0.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f355e605710>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "hidden_units = 300\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='constant',\n",
    "                activation='sigmoid')\n",
    "\n",
    "output_layer = Dense(units=n_classes,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "model.add(output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, to_categorical(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vary the hyperparameters. Choose differnet activations, kernal initializers, hidden units, optimizers, and optimizer parameters. To access optimizer parameters, instantiate optimizer objects from `tensorflow.keras.optimizers`. Can you get a better accuracy than 94%?\n",
    "\n",
    "This task might feel a little like looking for a needle in a haystack.  Perhaps you can think of an automated approach instead of a manual brute force search? (but with some intuition the brute force search will get you there, too.)  Keras has a [wrapper](https://keras.io/scikit-learn-api/) for the scikit-learn API where you can interface with GridSearch.  See this [blog post.](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 21s 346us/sample - loss: 0.4333 - accuracy: 0.8850\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 263us/sample - loss: 0.3153 - accuracy: 0.9107\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 15s 250us/sample - loss: 0.2869 - accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 15s 255us/sample - loss: 0.2676 - accuracy: 0.9199\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 27s 446us/sample - loss: 0.2516 - accuracy: 0.9247\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 27s 455us/sample - loss: 0.2492 - accuracy: 0.9257\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 391us/sample - loss: 0.2422 - accuracy: 0.9270\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 401us/sample - loss: 0.2398 - accuracy: 0.9273\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 394us/sample - loss: 0.2210 - accuracy: 0.9324\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 26s 438us/sample - loss: 0.2267 - accuracy: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f355a022400>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "\n",
    "model = Sequential() # sequence of layers\n",
    "\n",
    "hidden_units = 300\n",
    "n_classes = 10\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='constant',\n",
    "                activation='sigmoid')\n",
    "\n",
    "output_layer = Dense(units=n_classes,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='softmax')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "# model.add(Dense(units=hidden_units,\n",
    "#                 input_dim=hidden_units,\n",
    "#                 kernel_initializer='uniform',\n",
    "#                 activation='softmax'))\n",
    "model.add(output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, to_categorical(y_train), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. When you have a very good accuracy, make a picture of the weights associated with the hidden layers.\n",
    "\n",
    "Hint: do this, \n",
    "```python\n",
    "hidden_unit_i = 0\n",
    "plt.imshow(hidden_layer.weights[0].numpy()[:,hidden_unit_i].reshape(28,28))\n",
    "```\n",
    "\n",
    "Speculate on what this might mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f34fc2259b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFLZJREFUeJzt3V1slOeVB/D/4cNAjPk0GMc2UBAkfAYSK1mlEcqq2ypNKiW9iZqLiJWi0otGaqVeNMpebC6j1bZVLlaV6AaVRN20K7VREinabRatFBElUQzKBgKED2PAxjbfxhiDsX32wkPlJH7Pf5gZz4zz/H8Ssj1nXs/jd+YwH+d5zmPuDhFJz7RKD0BEKkPJL5IoJb9IopT8IolS8oskSskvkiglv0iilPwiiVLyiyRqRjlvbM6cOT5//vxy3qRIUvr6+jA4OGj5XLeo5DezxwC8AmA6gH9395ej68+fPx/PPvtsMTcpIoHXX3897+sW/LLfzKYD+DcA3wewHsAzZra+0N8nIuVVzHv+BwEcd/d2dx8C8EcAT5ZmWCIy2YpJ/iYAZ8b93Jm77EvMbIeZtZlZ2/Xr14u4OREppUn/tN/dd7p7q7u33nXXXZN9cyKSp2KSvwtAy7ifm3OXicgUUEzyfwJgjZl9y8xqAPwIwNulGZaITLaCS33uPmxmzwP4b4yV+na5++clG9kUUltbG8YHBgYm9fZnzMi+GxsbG8Njb968GcZZpyd2/IIFCzJjV65cCY+dNi1+bmJzRqKxs8+fBgcHw/jo6GhRx1eDour87v4ugHdLNBYRKSNN7xVJlJJfJFFKfpFEKflFEqXkF0mUkl8kUWVdzz+Z2NRhVpe9ceNGGI9qzmbx8um6urowPnv27DA+c+bMMB7NM7h48WJ47Jw5c8I4G3tT09eWc3xJNA+A/d01NTVhvKGhIYwfOnQoM7Z+fbwA9dq1a2G8v78/jPf19YXxaJ4Bu+1S0TO/SKKU/CKJUvKLJErJL5IoJb9IopT8Ion6xpT6hoaGwvjVq1fD+KJFi8L4rVu3MmOs1MeWps6bNy+ML1myJIxH5bzp06eHx7K/e8WKFWF81qxZYfzChQuZMbYUenh4OIx//PHHYXxkZCQzduzYsfBYdl5YKY+dd1ZaLgc984skSskvkiglv0iilPwiiVLyiyRKyS+SKCW/SKK+MXV+1mKa1aMPHDgQxqM20axezZaPsjbSbIlnFN+4cWN4LJtDwOrVZ8+eDeOnT5/OjLFzzrAlwWfOnMmMsccDWwLO5m6wOQgPPfRQZmzZsmVF3Xa+9Mwvkiglv0iilPwiiVLyiyRKyS+SKCW/SKKU/CKJKqrOb2YdAPoBjAAYdvfWUgwqS1SbjbapBoD29vYw3tPTU3Ccta9mLaZZvfrkyZNhvLe3NzPG+hywOQr19fVhPOpzAMRbdG/bti089siRI2E86hUAAEuXLs2MsfkJR48eDePNzc1hfNWqVWGc9Sooh1JM8vl7d4/vBRGpOnrZL5KoYpPfAfzVzPaZ2Y5SDEhEyqPYl/2PuHuXmS0F8J6ZHXH398dfIfefwg6Ab/0kIuVT1DO/u3flvp4D8CaABye4zk53b3X3VrafnoiUT8HJb2a1ZlZ3+3sA3wNwsFQDE5HJVczL/gYAb+baVs8A8B/u/l8lGZWITLqCk9/d2wHcV8KxhDVhIO7DHm0FDfD12ZcuXSo4vnXr1vBYtnac1ZyLqQmz3/3oo4+GcTaHYfHixWE86gfA6vjr1q0L4wMDA2E8qtWzv4t9PsX2Wli4cGEYj7Zdj/oQsNtmfS3GU6lPJFFKfpFEKflFEqXkF0mUkl8kUUp+kUSVtXX36OhoWJ5hyyA7OzszY2x5J5tduHbt2jAetddm7a8ZVlZi5ZuolfOaNWvCY++///4wzsqvbHvyqGzFWpJ/8MEHRd324OBgZmzu3LnhsWyLbnafsKXO0XJj9ru7u7szY6ykPZ6e+UUSpeQXSZSSXyRRSn6RRCn5RRKl5BdJlJJfJFFVtUV3VL8E4trp1atXw2P7+/vDeLTEEgAefvjhzBjbMrmYOj0AXLlyJYxv3rw5M8bq/HPmzAnjrM7f0dERxqO2421tbeGx+/fvD+PsvERjX7FiRXjs6tWrw/jly5eLikdzEFpaWsJjozknqvOLCKXkF0mUkl8kUUp+kUQp+UUSpeQXSZSSXyRRVVXnZ9siR22i2ZbJp0+fDuOsdXfUipn1Eoi20AZ4LX3+/PlhPFoXz2rlrAU1a4994MCBMH7wYPY+LsePHw+PZS2sWT+AqJ37hg0bwmPZlu9sW/Wo9wQA9PX1ZcZYL4HoscjGPZ6e+UUSpeQXSZSSXyRRSn6RRCn5RRKl5BdJlJJfJFG0KGhmuwD8AMA5d9+Yu2wRgD8BWAmgA8DT7h4vYMbYuvXa2trMOFtbfuPGjcwY2yqara9uaGgI41FNma0rZ70ChoaGwjjrRRDNM2A1Y3bb0Rbb+RwfzWFgx7L7lK1737ZtW2aMrddnW2y3t7eHcVbnj/aROH/+fMHHsr0Mxsvnmf/3AB77ymUvANjj7msA7Mn9LCJTCE1+d38fwFenvz0JYHfu+90AnirxuERkkhX6nr/B3W/33OoBEL9mFpGqU/QHfj7WoC6zSZ2Z7TCzNjNri3qPiUh5FZr8vWbWCAC5r+eyrujuO9291d1b2WaZIlI+hSb/2wC2577fDuCt0gxHRMqFJr+ZvQHgQwD3mFmnmT0H4GUA3zWzYwD+IfeziEwhtM7v7s9khL5zpzc2bdq0sEZ59uzZ8PjoMwNWC2f7sbOaclQ/ZbXwnp6eMM4+Cymmj/umTZvCY9kcBYbNjxgZGcmMPfDAA+Gxd999dxjfsmVLGF+5cmVmjM1/YPcZ6x/BejxE80ZYD4VSvX3WDD+RRCn5RRKl5BdJlJJfJFFKfpFEKflFElVVrbuLaWHNtsFm5TRWmolKQ2xparS1OAA0NjaGcdZWPCpDsvbWrLzK2o6z33/kyJHMGFu6ypbVshJrV1dXZoy1uGZjO3XqVBhfu3ZtGH/nnXcyYywPolIf2+79S9fN+5oi8o2i5BdJlJJfJFFKfpFEKflFEqXkF0mUkl8kUWWt84+Ojob1dlarj2qYbGkqawvO6tVRLf+jjz4Kj2XLhZcvXx7GmehvY0udu7u7w3jULh3g8wT27duXGbv33nvDY2fNmhXGv/jiizA+OjqaGRseHg6PZY/FpqamMM7OW11dXWasvr4+PJaNLV965hdJlJJfJFFKfpFEKflFEqXkF0mUkl8kUUp+kURV1Xr+q1evhvGotsrWMff19YXxmzdvhvE9e/Zkxtja7ieeeCKMs/X6UR8DAKipqcmMsVo5q3dHtXKAn7dly5Zlxth9xs4Lm5sxODiYGZs3b1547OzZswv+3QCv82/evDkzxnpPROet1Ft0i8g3kJJfJFFKfpFEKflFEqXkF0mUkl8kUUp+kUTROr+Z7QLwAwDn3H1j7rKXAPwYwO3m5i+6+7vFDoZtPRzVMFndldWj2XbP0Zp81vOfrZlnNeeOjo4wHvUDYL0E2Lr0EydOhHE2jyDa74DV0qP5CwDQ2dkZxqN5I2wLbrY9+MWLF8M4s2TJkswY204+mt9wJ2v983nm/z2Axya4/DfuviX3r+jEF5Hyosnv7u8DiKdaiciUU8x7/ufN7DMz22Vm8b5KIlJ1Ck3+3wJYDWALgG4Av8q6opntMLM2M2tjc5ZFpHwKSn5373X3EXcfBfA7AA8G193p7q3u3so+0BOR8iko+c1s/LayPwRwsDTDEZFyyafU9waARwHUm1kngH8G8KiZbQHgADoA/GQSxygik4Amv7s/M8HFr07CWDBz5swwHtXqWa/zpUuXhnG2/jqqxbNaOasps1r5xo0bw3hzc3NmjH3OwnoosHkC0Xp9ADh06FBmjM29WLNmTRhn+9hHff1ZL4AzZ86EcbZuPprfAAAjIyOZMfZYjMbO+i+Mpxl+IolS8oskSskvkiglv0iilPwiiVLyiySqqlp3M5cvX86MNTY2ZsYA3l57xoz4VESlvsOHD4fHNjQ0hHG2Rffq1avDeFTyYluTs/bYbFZmV1dXGGflvAhb6nzfffeF8VWrVmXG9u7dGx7Lyohs6SyLR1ubT58+PTyWPVbzpWd+kUQp+UUSpeQXSZSSXyRRSn6RRCn5RRKl5BdJVFXV+dmWzVGc1aNZrby9vT2Mnz9/PjPG6rKsDfTWrVuLOj7awjuqJwO8Ds/akkdLU4F4aeutW7fCY9l5HRgYCOPRsls2R4CdFzZ2tmT43LlzYTwStf2+E3rmF0mUkl8kUUp+kUQp+UUSpeQXSZSSXyRRSn6RRFVVnZ/VbaN18azOz+quxayhZm3D77nnnjDOehEwJ0+ezIxFPRAAfs5ZG+m6urowHvUqYC3Lo/kLAP/bTp8+XfBtsx4MfX19YXxoaCiMR+e1VHV8Rs/8IolS8oskSskvkiglv0iilPwiiVLyiyRKyS+SKFrnN7MWAK8BaADgAHa6+ytmtgjAnwCsBNAB4Gl3jwuvRYpq0qwmzOrVmzZtCuPDw8MFxQC+XTPr8c7Wjkdbm7M5BGyradY7f3BwMIx3dnZmxti26XPnzg3j0fwGIB4bO+ds63LW/4HtZxDNS5k9e3Z4bKnk88w/DOAX7r4ewN8B+KmZrQfwAoA97r4GwJ7czyIyRdDkd/dud9+f+74fwGEATQCeBLA7d7XdAJ6arEGKSOnd0Xt+M1sJYCuAjwE0uHt3LtSDsbcFIjJF5J38ZjYXwJ8B/Nzdv/SGyMfeQE34JsrMdphZm5m1Xb9+vajBikjp5JX8ZjYTY4n/B3f/S+7iXjNrzMUbAUzYkdDdd7p7q7u3ssU3IlI+NPlt7OPgVwEcdvdfjwu9DWB77vvtAN4q/fBEZLLks6T32wCeBXDAzD7NXfYigJcB/KeZPQfgFICnix0M2046KmmxFtKLFy8u+HcD8RJQdixz4sSJMN7f3x/GV6xYkRljJa2oJTnA24azsUVLW9kyajY2VhKL7hfWOpst2e3t7Q3j7C1utGyX/V2sbJ0vmvzuvhdAVjH4OyUZhYiUnWb4iSRKyS+SKCW/SKKU/CKJUvKLJErJL5KoqmrdzURLZ2tqasJj2ZLf2traMN7T01Pw72YzG48cORLG2dLVqKbc3d2dGQP4kt4rV66EcTaPoKmpKTPGlr2yWjybJxDNzWCttdnfzeY/XLp0KYxHW4CzOQTs8ZYvPfOLJErJL5IoJb9IopT8IolS8oskSskvkiglv0iiplSdP1qzz+qybG04W5Pf0tJS8O9mNV+2dpytDY/q5dE21QBvC75u3bowznowRO2zWftrVs9m695HR0czY+zxws75+vXrwzjb4js6b6w3RanomV8kUUp+kUQp+UUSpeQXSZSSXyRRSn6RRCn5RRI1per8bO14hK0NX758eRi/du1aZoytDWd7BkybFv8fzGrGUR/3aE07UFytHACOHj0axmfMyH6Isdu+cOFCGGfbh0fn5cMPPwyPZY8HNja23j+aX8F6LJSKnvlFEqXkF0mUkl8kUUp+kUQp+UUSpeQXSZSSXyRRtM5vZi0AXgPQAMAB7HT3V8zsJQA/BnB7MfuL7v7uZA2UYeuzFy1aFMbZuveoXr106dLw2IULF4ZxVuevr68P43V1dZmxYvYjAPh5i+Y/APHcjNbW1vBYtg89628frYtnfQzYfdbZ2RnGGxsbw3j0eCqXfEYwDOAX7r7fzOoA7DOz93Kx37j7v07e8ERkstDkd/duAN257/vN7DCA7G1YRGRKuKP3/Ga2EsBWAB/nLnrezD4zs11mNuHrJDPbYWZtZtbGWiOJSPnknfxmNhfAnwH83N2vAvgtgNUAtmDslcGvJjrO3Xe6e6u7t7I960SkfPJKfjObibHE/4O7/wUA3L3X3UfcfRTA7wA8OHnDFJFSo8lvY0uMXgVw2N1/Pe7y8R9n/hDAwdIPT0QmSz6f9n8bwLMADpjZp7nLXgTwjJltwVj5rwPATyZlhHkaGBgI42wJZrT9NxBvB93f3x8ee/z48TDOluxG2zkDwKlTpzJjrKTFSqSXL18O46xMGbWoZsuNWVvwM2fOhPGOjo7M2IIFC8JjWXmV3WdRy/Jqkc+n/XsBTLTAuGI1fREpnmb4iSRKyS+SKCW/SKKU/CKJUvKLJErJL5Koyq8rLBG2dHUyl1CyOQKsXs1aNbOlq83NzZkx9nezeQCsvTYbW1RrZ8du2LAhjLNa+sqVKzNjrO03u09ZS/OpQM/8IolS8oskSskvkiglv0iilPwiiVLyiyRKyS+SKCtm2+s7vjGz8wDGLz6vBxAvtK+cah1btY4L0NgKVcqxrXD3JflcsazJ/7UbN2tz97h5e4VU69iqdVyAxlaoSo1NL/tFEqXkF0lUpZN/Z4VvP1KtY6vWcQEaW6EqMraKvucXkcqp9DO/iFRIRZLfzB4zsy/M7LiZvVCJMWQxsw4zO2Bmn5pZW4XHssvMzpnZwXGXLTKz98zsWO5rvJ1secf2kpl15c7dp2b2eIXG1mJm/2tmh8zsczP7We7yip67YFwVOW9lf9lvZtMBHAXwXQCdAD4B8Iy7HyrrQDKYWQeAVneveE3YzLYBuAbgNXffmLvsXwBccveXc/9xLnT3X1bJ2F4CcK3SOzfnNpRpHL+zNICnAPwjKnjugnE9jQqct0o88z8I4Li7t7v7EIA/AniyAuOoeu7+PoBLX7n4SQC7c9/vxtiDp+wyxlYV3L3b3ffnvu8HcHtn6Yqeu2BcFVGJ5G8CMH6rlU5U15bfDuCvZrbPzHZUejATaMhtmw4APQDirWPKj+7cXE5f2Vm6as5dITtel5o+8Pu6R9z9fgDfB/DT3MvbquRj79mqqVyT187N5TLBztJ/U8lzV+iO16VWieTvAtAy7ufm3GVVwd27cl/PAXgT1bf7cO/tTVJzX89VeDx/U007N0+0szSq4NxV047XlUj+TwCsMbNvmVkNgB8BeLsC4/gaM6vNfRADM6sF8D1U3+7DbwPYnvt+O4C3KjiWL6mWnZuzdpZGhc9d1e147e5l/wfgcYx94n8CwD9VYgwZ41oF4P9y/z6v9NgAvIGxl4G3MPbZyHMAFgPYA+AYgP8BsKiKxvY6gAMAPsNYojVWaGyPYOwl/WcAPs39e7zS5y4YV0XOm2b4iSRKH/iJJErJL5IoJb9IopT8IolS8oskSskvkiglv0iilPwiifp/pamDl+p5s68AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_unit_i = 0\n",
    "plt.imshow(hidden_layer.weights[0].numpy()[:,hidden_unit_i].reshape(28,28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation for PCs with NVIDIA GPUs that wish to use the GPU to speed up training.  \n",
    "\n",
    "1) Go [here](https://github.com/NVIDIA/nvidia-docker) and follow the directions to install `nvidia-docker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Check that it works:  \n",
    "   ```bash\n",
    "   $ docker run --gpus all nvidia/cuda:9.0-base nvidia-smi\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Download an image, make a container and a volume:\n",
    "   ```\n",
    "   $ cd ~\n",
    "   $ docker run --gpus all -it --name tensorflow-gpu -p 8888:8888 -v \"$PWD\":/tf tensorflow/tensorflow:latest-gpu-py3-jupyter\n",
    "   ```\n",
    "\n",
    "As discussed in Part I, you can work with the container in a Jupyter notebook or from terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
